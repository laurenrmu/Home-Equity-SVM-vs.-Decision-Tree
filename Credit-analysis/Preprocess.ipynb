{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "#os.system('cls')\n",
    "df = pd.read_csv('C:/Users/laure/Credit-analysis/hmeq.csv')\n",
    "pd.set_option('display.max_columns', 50,'display.max_rows',50)\n",
    "col_names = df.columns.values.tolist()\n",
    "\n",
    "#print(\"The shape of the data frame is \", df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Missing values display\n",
    "\n",
    "#header_miss_percent= df.isnull().sum()/len(df)*100\n",
    "\n",
    "#item_miss_percent =   (df.isnull().sum(axis=1))/13\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete rows with missing values of >= 50%\n",
    "\n",
    "df = df[(df.isnull().sum(axis=1))/13 <= (3/13)]\n",
    "\n",
    "#print(\"The shape of the data frame after row deletions with 4 or more missing values is\", df.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert nominal data using one hot encoding\n",
    "\n",
    "dummies_1  = pd.get_dummies(df.REASON)\n",
    "dummies_2 = pd.get_dummies(df.JOB)\n",
    "df = df.drop(['REASON','JOB'], axis =1)\n",
    "df = pd.concat([df,dummies_1,dummies_2], axis =1)\n",
    "\n",
    "\n",
    "col_names = df.columns.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split to training/validation and testing data\n",
    "\n",
    "X_train, X_test = train_test_split(df,test_size = .3)\n",
    "X_test, X_val = train_test_split(X_test, test_size=.5)\n",
    "\n",
    "\n",
    "\n",
    "train_y = X_train.iloc[:,0]\n",
    "x = X_train.iloc[:,1:]\n",
    "\n",
    "test_y = X_test.iloc[:,0]\n",
    "validation_y = X_val.iloc[:,0]\n",
    "\n",
    "\n",
    "\n",
    "#Normalize the data\n",
    "\n",
    "def norm_data(dataframe):\n",
    "    return( (dataframe - dataframe.min())/(dataframe.max() - dataframe.min()))\n",
    "\n",
    "X_train = X_train.apply(norm_data)\n",
    "X_test = X_test.apply(norm_data)\n",
    "X_val = X_val.apply(norm_data)\n",
    "\n",
    "\n",
    "\n",
    "#impute missing values\n",
    "imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "X_train = imputer.fit_transform(X_train.values.tolist())\n",
    "X_test =  imputer.fit_transform(X_test.values.tolist())\n",
    "X_val = imputer.fit_transform(X_val.values.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the data for use in different models\n",
    "\n",
    "#train,test,val X\n",
    "np.savetxt('C:/Users/laure/Credit-analysis/train_x.csv',X_train, delimiter=',', fmt='%d')\n",
    "np.savetxt('C:/Users/laure/Credit-analysis/test_x.csv',X_test,delimiter=',', fmt='%d')\n",
    "np.savetxt('C:/Users/laure/Credit-analysis/validation_x.csv',X_val,delimiter=',', fmt='%d')\n",
    "\n",
    "#train, test, val y\n",
    "np.savetxt('C:/Users/laure/Credit-analysis/test_y.csv', test_y,delimiter=',', fmt='%d')\n",
    "np.savetxt('C:/Users/laure/Credit-analysis/train_y.csv',train_y,delimiter=',', fmt='%d')\n",
    "np.savetxt('C:/Users/laure/Credit-analysis/validation_y.csv',validation_y,delimiter=',', fmt='%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3934, 19) (843, 19) (844, 19) (5621, 19)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape,X_val.shape,df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
